

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Welcome to Elastic Hadoop on OpenStack documentation! &mdash; Elastic Hadoop on OpenStack 0.1 documentation</title>
    
    <link rel="stylesheet" href="_static/sphinxdoc.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/tweaks.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '',
        VERSION:     '0.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/jquery.tweet.js"></script>
    <link rel="top" title="Elastic Hadoop on OpenStack 0.1 documentation" href="#" />
    <link rel="next" title="Elastic Hadoop on OpenStack Architecture (draft)" href="architecture.html" />
    <script type='text/javascript'>
        /*$(document).ready(function(){
            $("#twitter_feed").tweet({
                username: "openstack",
                query: "from:openstack",
                avatar_size: 32,
                count: 4,
                loading_text: "loading tweets..."
            });
        });*/
    </script>

  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="http-routingtable.html" title="HTTP Routing Table"
             >routing table</a> |</li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="architecture.html" title="Elastic Hadoop on OpenStack Architecture (draft)"
             accesskey="N">next</a> |</li>
        <li><a href="#">Elastic Hadoop on OpenStack 0.1 documentation</a> &raquo;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
            <h3><a href="#">Table Of Contents</a></h3>
            <ul>
<li><a class="reference internal" href="#">Welcome to Elastic Hadoop on OpenStack documentation!</a><ul>
<li><a class="reference internal" href="#introduction">Introduction</a></li>
<li><a class="reference internal" href="#details">Details</a></li>
<li><a class="reference internal" href="#general-workflow">General Workflow</a></li>
<li><a class="reference internal" href="#user-s-perspective">User&#8217;s Perspective</a></li>
<li><a class="reference internal" href="#integration-with-swift">Integration with Swift</a></li>
<li><a class="reference internal" href="#pluggable-deployment-and-monitoring">Pluggable Deployment and Monitoring</a></li>
<li><a class="reference internal" href="#useful-links">Useful links</a><ul>
</ul>
</li>
</ul>
</li>
</ul>

            <h4>Next topic</h4>
            <p class="topless"><a href="architecture.html"
                                  title="next chapter">Elastic Hadoop on OpenStack Architecture (draft)</a></p>
            <h3>This Page</h3>
            <ul class="this-page-menu">
              <li><a href="_sources/index.txt"
                     rel="nofollow">Show Source</a></li>
            </ul>
          <div id="searchbox" style="display: none">
            <h3>Quick search</h3>
              <form class="search" action="search.html" method="get">
                <input type="text" name="q" size="18" />
                <input type="submit" value="Go" />
                <input type="hidden" name="check_keywords" value="yes" />
                <input type="hidden" name="area" value="default" />
              </form>
              <p class="searchtip" style="font-size: 90%">
              Enter search terms or a module, class or function name.
              </p>
          </div>
          <script type="text/javascript">$('#searchbox').show(0);</script>
          <!--
          <h3>Twitter Feed</h3>
          <div id="twitter_feed" class='twitter_feed'></div>
          -->
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="welcome-to-elastic-hadoop-on-openstack-documentation">
<h1>Welcome to Elastic Hadoop on OpenStack documentation!<a class="headerlink" href="#welcome-to-elastic-hadoop-on-openstack-documentation" title="Permalink to this headline">¶</a></h1>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>Apache Hadoop is an industry standard and widely adopted MapReduce implementation.
The aim of this project is to enable users to easily provision and manage Hadoop clusters on OpenStack.
It is worth mentioning that Amazon provides Hadoop for several years as Amazon Elastic MapReduce (EMR) service.</p>
<p>EHO aims to provide users with simple means to provision a Hadoop cluster by specifying several parameters
like Hadoop version, cluster topology, nodes hardware details and a few more. After user fills in all the parameters,
EHO deploys the cluster in a few minutes. Also EHO provides means to scale already provisioned cluster by
adding/removing worker nodes on demand.</p>
<p>Fast and simple provision means that EHO will be convenient for deploying Hadoop for various purposes.
For instance, user could quickly create a cluster for experiments, play with it and then kill the cluster without
regret.
At the same time limited user&#8217;s input and automated provisioning
means that an on-demand cluster could be created for each job, instead of running all jobs on a single permanent
cluster.
That is similar to what Amazon EMR service offers.</p>
<p>EHO is designed to be pluggable framework integrated with existing and widely adopted management solutions
(Apache Ambari, Cloudera Management Console) and supporting various Hadoop versions on different OSes.</p>
<p>EHO will extend OpenStack Dashboard to keep it up as a single endpoint for managing all cloud services.
The ultimate goal of EHO GUI is to provide one-click cluster provisioning and job execution.</p>
<p>The main idea of the project is implementation of MapReduce service for OpenStack similar to Amazon EMR.</p>
</div>
<div class="section" id="details">
<h2>Details<a class="headerlink" href="#details" title="Permalink to this headline">¶</a></h2>
<p>The EHO product communicates with the following OpenStack components:</p>
<ul class="simple">
<li>Horizon - provides GUI with ability to use all of EHO&#8217;s features</li>
<li>Keystone - authenticates users and provides security token that is used to work with the OpenStack,
hence limiting user abilities in EHO to his OpenStack privileges</li>
<li>Nova - is used to provision VMs for Hadoop Cluster</li>
<li>Glance - Hadoop VM images are stored there, each image containing an installed OS and Hadoop;
the pre-installed Hadoop should give us good handicap on node start-up</li>
<li>Swift - storage for data that will be processed by Hadoop jobs</li>
</ul>
<img alt="_images/openstack-interop.png" src="_images/openstack-interop.png" />
</div>
<div class="section" id="general-workflow">
<h2>General Workflow<a class="headerlink" href="#general-workflow" title="Permalink to this headline">¶</a></h2>
<p>EHO provides several kinds of Hadoop cluster topology. JobTracker and NameNode processes could be run
either on a single VM or two separate ones. Also cluster could contain worker nodes of different types.
Worker nodes could run both TaskTracker and DataNode, or either of these processes alone.
EHO allows user to create cluster with any combination of these options.
It only validates that cluster topology has exactly one JobTracker and one NameNode processes.</p>
<p>EHO is designed to have pluggable deployment mechanism. It allows to provision Hadoop cluster with various approaches,
including existing management/deployment solutions like OpenStack Heat, Apache Ambari and Cloudera Management Console.</p>
<p>A reference implementation will be provided for deployment mechanism which does fast cluster provisioning using
pre-installed Hadoop image. Image is a disk with installed OS and Hadoop, and that gives user an ability to select
both Hadoop and Linux distributions he wishes to use. The implementation has some pre-built images. Also users will
be provided with a guide on how to create custom image in case pre-built ones are not sufficient.</p>
</div>
<div class="section" id="user-s-perspective">
<h2>User&#8217;s Perspective<a class="headerlink" href="#user-s-perspective" title="Permalink to this headline">¶</a></h2>
<p>While provisioning cluster through EHO, user operates on two types of entities: Node Templates and Clusters.</p>
<p>Node Template describes a node within cluster and it has several parameters. Node type determines which Hadoop
processes will be running on the node and thereby its role in the cluster. It could be either of JobTracker, NameNode,
TaskTracker or DataNode, or any combination of these. Also template encapsulates hardware parameters for the node VM
and configuration for Hadoop processes running on the node.</p>
<p>Cluster simply represents Hadoop Cluster. It is mainly characterized by Hadoop image which will be used for cluster
deployment and cluster topology. The topology is a list of node templates and respectively amount of nodes being
deployed for each template. With respect to topology, EHO checks only that cluster has one JobTracker and one NameNode.</p>
<p>Each node template and cluster belongs to some tenant determined by user. Users have access only to objects located
in tenants they have access to. Users could edit/delete only objects they created. Naturally admin users have full
access to every object. That way EHO complies with general OpenStack access policy.</p>
</div>
<div class="section" id="integration-with-swift">
<h2>Integration with Swift<a class="headerlink" href="#integration-with-swift" title="Permalink to this headline">¶</a></h2>
<p>The Swift service is a standard file storage in OpenStack environment, analog of Amazon S3. As a rule it is deployed
on bare metal machines. It is natural to expect Hadoop on OpenStack to process data stored there. There are a couple
of enhancements on the way which can help there.</p>
<p>First, a FileSystem implementation for Swift: <a class="reference external" href="https://issues.apache.org/jira/browse/HADOOP-8545/">HADOOP-8545</a>.
With that thing in place, Hadoop jobs can work with Swift as naturally as with HDFS.</p>
<p>On the Swift side, we have the change request: <a class="reference external" href="https://review.openstack.org/#/c/21015/">Change I6b1ba25b</a>.
It implements the ability to list endpoints for an object, account or container, to make it possible to integrate
swift with software that relies on data locality information to avoid network overhead.</p>
<p>HDFS is not that reliable in virtual environment. Assume the following example: we have HDFS deployed in OpenStack.
If we store a file in HDFS with replication factor 3, it could happen that all 3 replicas of the file will be stored
on VMs running on a single compute node. In that case the node failure will cause file loss.</p>
<p>The problem becomes even more complex if HDFS nodes use external volumes as disks. In that case it could also happen
that all 3 volumes storing file replicas are located on the same cinder node. Similarly, if that node fails,
file is also lost.</p>
<p>Still, it makes sense to deploy data nodes on task tracker VMs. HDFS deployed in such a way could be used to store
intermediate data for a sequence of jobs. Both input of the first job and output of the last one could be reliably
stored in Swift.</p>
</div>
<div class="section" id="pluggable-deployment-and-monitoring">
<h2>Pluggable Deployment and Monitoring<a class="headerlink" href="#pluggable-deployment-and-monitoring" title="Permalink to this headline">¶</a></h2>
<p>It was already mentioned in &#8220;General Workflow&#8221; that deployment mechanism will be pluggable allowing user to use
existing solutions to provision Hadoop cluster.</p>
<p>The same applies to monitoring. Instead of relying on its own monitoring module, EHO provides a capability to
plug in an existing solution like Nagios and Zabbix.</p>
<p>Both deployment and monitoring tools will be installed on stand-alone VMs, thus allowing a single instance to
manage/monitor several clusters at once.</p>
</div>
<div class="section" id="useful-links">
<h2>Useful links<a class="headerlink" href="#useful-links" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">Elastic Hadoop on OpenStack Architecture (draft)</a></li>
<li class="toctree-l1"><a class="reference internal" href="restapi/v02.html">EHO REST API v0.2</a><ul>
<li class="toctree-l2"><a class="reference internal" href="restapi/v02.html#general-api-information">1 General API information</a><ul>
<li class="toctree-l3"><a class="reference internal" href="restapi/v02.html#authentication-and-authorization">1.1 Authentication and Authorization</a></li>
<li class="toctree-l3"><a class="reference internal" href="restapi/v02.html#request-response-types">1.2 Request / Response Types</a></li>
<li class="toctree-l3"><a class="reference internal" href="restapi/v02.html#filtering-and-column-selection">1.3 Filtering and Column Selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="restapi/v02.html#faults">1.4 Faults</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="restapi/v02.html#object-model">2 Object Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="restapi/v02.html#node-template-object">2.1 Node Template object</a></li>
<li class="toctree-l3"><a class="reference internal" href="restapi/v02.html#cluster-create-update-object">2.2 Cluster Create/Update object</a></li>
<li class="toctree-l3"><a class="reference internal" href="restapi/v02.html#cluster-object">2.3 Cluster object</a></li>
<li class="toctree-l3"><a class="reference internal" href="restapi/v02.html#node-object">2.4 Node object</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="restapi/v02.html#api-operations">3 API operations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="restapi/v02.html#node-templates-ops">3.1 Node Templates ops</a></li>
<li class="toctree-l3"><a class="reference internal" href="restapi/v02.html#list-all-node-templates">3.1.2 List all Node Templates</a></li>
<li class="toctree-l3"><a class="reference internal" href="restapi/v02.html#create-a-node-template">3.1.3 Create a Node Template</a></li>
<li class="toctree-l3"><a class="reference internal" href="restapi/v02.html#retrieve-a-specific-node-template">3.1.4 Retrieve a specific Node Template</a></li>
<li class="toctree-l3"><a class="reference internal" href="restapi/v02.html#update-a-node-template">3.1.5 Update a Node Template</a></li>
<li class="toctree-l3"><a class="reference internal" href="restapi/v02.html#remove-a-node-template">3.1.6 Remove a Node Template</a></li>
<li class="toctree-l3"><a class="reference internal" href="restapi/v02.html#clusters-ops">3.2 Clusters ops</a></li>
<li class="toctree-l3"><a class="reference internal" href="restapi/v02.html#list-all-clusters">3.2.2 List all clusters</a></li>
<li class="toctree-l3"><a class="reference internal" href="restapi/v02.html#create-a-cluster">3.2.3 Create a cluster</a></li>
<li class="toctree-l3"><a class="reference internal" href="restapi/v02.html#retrieve-a-specific-cluster">3.2.4 Retrieve a specific cluster</a></li>
<li class="toctree-l3"><a class="reference internal" href="restapi/v02.html#update-a-cluster">3.2.5 Update a cluster</a></li>
<li class="toctree-l3"><a class="reference internal" href="restapi/v02.html#remove-a-cluster">3.2.6 Remove a cluster</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="http-routingtable.html" title="HTTP Routing Table"
             >routing table</a> |</li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="architecture.html" title="Elastic Hadoop on OpenStack Architecture (draft)"
             >next</a> |</li>
        <li><a href="#">Elastic Hadoop on OpenStack 0.1 documentation</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2013, Mirantis Inc..
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.3.
    </div>
  </body>
</html>